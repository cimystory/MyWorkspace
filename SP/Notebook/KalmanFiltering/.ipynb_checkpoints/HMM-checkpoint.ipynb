{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'urllib2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-88b914871289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhmmlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhmm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0murllib2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mBeautifulSoup\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'urllib2'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "from matplotlib import cm, pyplot as plt\n",
    "from matplotlib.dates import YearLocator, MonthLocator\n",
    "try:\n",
    "    from matplotlib.finance import quotes_historical_yahoo_ochl\n",
    "except ImportError:\n",
    "    # For Matplotlib prior to 1.5.\n",
    "    from matplotlib.finance import (\n",
    "        quotes_historical_yahoo as quotes_historical_yahoo_ochl\n",
    "    )\n",
    "from hmmlearn import hmm\n",
    "import urllib2\n",
    "from BeautifulSoup import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMMs:\n",
      "~  Probabilistic model where a sequence of variables (X) is generated by a sequence of internal hidden states (Z) ~\n",
      "-Transition between hidden states are determined by a probability vector (π) and a transition probability matrix (A)\n",
      "-The emission probability of an observable can be any distribution with parameters (Ω) conditioned on the current hidden state.\n",
      "                    fundamental principles of HMMS:\n",
      "1.  Given the model parameters and observed data, estimate the optimal sequence of hidden states.\n",
      "\t--> Viterbi Algorithm  \n",
      "2.  Given the model parameters and observed data, calculate the likelihood of the data.\n",
      "\t--> Forward-Backward Algorithm  \n",
      "3.  Given just the observed data, estimate the model parameters.\n",
      "\t--> EM Algorithm  \n"
     ]
    }
   ],
   "source": [
    "# HMM tutorial\n",
    "print(\"HMMs:\")\n",
    "print(\"~  Probabilistic model where a sequence of variables (X) is generated by a sequence of internal hidden states (Z) ~\")\n",
    "print(\"-Transition between hidden states are determined by a probability vector (π) and a transition probability matrix (A)\")\n",
    "print(\"-The emission probability of an observable can be any distribution with parameters (Ω) conditioned on the current hidden state.\")\n",
    "print(\"                    fundamental principles of HMMS:\")\n",
    "print(\"1.  Given the model parameters and observed data, estimate the optimal sequence of hidden states.\")\n",
    "print(\"\\t--> Viterbi Algorithm  \")\n",
    "print(\"2.  Given the model parameters and observed data, calculate the likelihood of the data.\")\n",
    "print(\"\\t--> Forward-Backward Algorithm  \")\n",
    "print(\"3.  Given just the observed data, estimate the model parameters.\")\n",
    "print(\"\\t--> EM Algorithm  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Viterbi Algorithm\n",
    "def viterbi(obs, states, start_p, trans_p, emit_p):\n",
    "    V = [{}]\n",
    "    for st in states:\n",
    "        V[0][st] = {\"prob\": start_p[st] * emit_p[st][obs[0]], \"prev\": None}\n",
    "    # Run Viterbi when t > 0\n",
    "    for t in range(1, len(obs)):\n",
    "        V.append({})\n",
    "        for st in states:\n",
    "            max_tr_prob = max(V[t-1][prev_st][\"prob\"]*trans_p[prev_st][st] for prev_st in states)\n",
    "            for prev_st in states:\n",
    "                if V[t-1][prev_st][\"prob\"] * trans_p[prev_st][st] == max_tr_prob:\n",
    "                    max_prob = max_tr_prob * emit_p[st][obs[t]]\n",
    "                    V[t][st] = {\"prob\": max_prob, \"prev\": prev_st}\n",
    "                    break\n",
    "    for line in dptable(V):\n",
    "        print(line)\n",
    "    opt = []\n",
    "    # The highest probability\n",
    "    max_prob = max(value[\"prob\"] for value in V[-1].values())\n",
    "    previous = None\n",
    "    # Get most probable state and its backtrack\n",
    "    for st, data in V[-1].items():\n",
    "        if data[\"prob\"] == max_prob:\n",
    "            opt.append(st)\n",
    "            previous = st\n",
    "            break\n",
    "    # Follow the backtrack till the first observation\n",
    "    for t in range(len(V) - 2, -1, -1):\n",
    "        opt.insert(0, V[t + 1][previous][\"prev\"])\n",
    "        previous = V[t + 1][previous][\"prev\"]\n",
    "\n",
    "    print('The steps of states are [ ' + ' '.join(opt) + ' ] with highest probability of %s' % max_prob)\n",
    "\n",
    "def dptable(V):\n",
    "    # Print a table of steps from dictionary\n",
    "    yield(\" \".join((\"%12d\" % i) for i in range(len(V))))\n",
    "    for state in V[0]:\n",
    "        yield(\"%.7s: \" % state + \" \".join(\"%.7s\" % (\"%f\" % v[state][\"prob\"]) for v in V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This example demonstrates the Viterbi algorithm\n",
      "Context: Based on a sequence of observed symptoms (normal, cold, dizzy) and possible hidden states (healthy, fever)\n",
      "  ~ What is the most likely sequence of health conditions of the patient that would explain these observations?\n",
      "\n",
      "- Sequence of Observations:  ('normal', 'cold', 'dizzy')\n",
      "- Hidden States:  ('Healthy', 'Fever')\n",
      "- Start Probability:  {'Healthy': 0.6, 'Fever': 0.4}\n",
      "- Transmission Probabilities:  {'Healthy': {'Healthy': 0.7, 'Fever': 0.3}, 'Fever': {'Healthy': 0.4, 'Fever': 0.6}}\n",
      "- Emission Probabilities:  {'Healthy': {'normal': 0.5, 'cold': 0.4, 'dizzy': 0.1}, 'Fever': {'normal': 0.1, 'cold': 0.3, 'dizzy': 0.6}} \n",
      "\n",
      "Results:\n",
      "           0            1            2\n",
      "Healthy: 0.30000 0.08400 0.00588\n",
      "Fever: 0.04000 0.02700 0.01512\n",
      "The steps of states are [ Healthy Healthy Fever ] with highest probability of 0.01512\n"
     ]
    }
   ],
   "source": [
    "# Example of Viterbi algorithm in action\n",
    "print(\"This example demonstrates the Viterbi algorithm\")\n",
    "print(\"Context: Based on a sequence of observed symptoms (normal, cold, dizzy) and possible hidden states (healthy, fever)\")\n",
    "print(\"  ~ What is the most likely sequence of health conditions of the patient that would explain these observations?\\n\")   \n",
    "obs = ('normal', 'cold', 'dizzy')\n",
    "states = ('Healthy', 'Fever')\n",
    "start_p = {'Healthy': 0.6, 'Fever': 0.4}\n",
    "trans_p = {\n",
    "   'Healthy' : {'Healthy': 0.7, 'Fever': 0.3},\n",
    "   'Fever' : {'Healthy': 0.4, 'Fever': 0.6}\n",
    "   }\n",
    "emit_p = {\n",
    "   'Healthy' : {'normal': 0.5, 'cold': 0.4, 'dizzy': 0.1},\n",
    "   'Fever' : {'normal': 0.1, 'cold': 0.3, 'dizzy': 0.6}\n",
    "   }\n",
    "print(\"- Sequence of Observations: \",obs)\n",
    "print(\"- Hidden States: \",states)\n",
    "print(\"- Start Probability: \",start_p)\n",
    "print(\"- Transmission Probabilities: \",trans_p)\n",
    "print(\"- Emission Probabilities: \",emit_p,\"\\n\")\n",
    "\n",
    "print(\"Results:\")\n",
    "viterbi(obs,states,start_p,trans_p,emit_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forward-Backward Algorithm\n",
    "def fwd_bkw(observations, states, start_prob, trans_prob, emm_prob, end_st):\n",
    "    # forward part of the algorithm\n",
    "    fwd = []\n",
    "    f_prev = {}\n",
    "    for i, observation_i in enumerate(observations):\n",
    "        f_curr = {}\n",
    "        for st in states:\n",
    "            if i == 0:\n",
    "                # base case for the forward part\n",
    "                prev_f_sum = start_prob[st]\n",
    "            else:\n",
    "                prev_f_sum = sum(f_prev[k]*trans_prob[k][st] for k in states)\n",
    "\n",
    "            f_curr[st] = emm_prob[st][observation_i] * prev_f_sum\n",
    "\n",
    "        fwd.append(f_curr)\n",
    "        f_prev = f_curr\n",
    "\n",
    "    p_fwd = sum(f_curr[k] * trans_prob[k][end_st] for k in states)\n",
    "\n",
    "    # backward part of the algorithm\n",
    "    bkw = []\n",
    "    b_prev = {}\n",
    "    for i, observation_i_plus in enumerate(reversed(observations[1:]+(None,))):\n",
    "        b_curr = {}\n",
    "        for st in states:\n",
    "            if i == 0:\n",
    "                # base case for backward part\n",
    "                b_curr[st] = trans_prob[st][end_st]\n",
    "            else:\n",
    "                b_curr[st] = sum(trans_prob[st][l] * emm_prob[l][observation_i_plus] * b_prev[l] for l in states)\n",
    "\n",
    "        bkw.insert(0,b_curr)\n",
    "        b_prev = b_curr\n",
    "\n",
    "    p_bkw = sum(start_prob[l] * emm_prob[l][observations[0]] * b_curr[l] for l in states)\n",
    "\n",
    "    # merging the two parts\n",
    "    posterior = []\n",
    "    for i in range(len(observations)):\n",
    "        posterior.append({st: fwd[i][st] * bkw[i][st] / p_fwd for st in states})\n",
    "\n",
    "    assert p_fwd == p_bkw\n",
    "    return fwd, bkw, posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This example demonstrates the Forward-Backward algorithm\n",
      "The Forware-Backward Algorithm consists of 3 steps:\n",
      "1.  Computing forward probabilities\n",
      "\t -  the probability of ending up in any particular state given the first k observations in the sequence\n",
      "2.  Computing backward probabilities\n",
      "\t -  the probability of observing the remaining observations given any starting point k\n",
      "3.  computing smoothed values.\n",
      "\n",
      "- Sequence of Observations:  ('normal', 'cold', 'dizzy')\n",
      "- Hidden States:  ('Healthy', 'Fever')\n",
      "- Start Probability:  {'Healthy': 0.6, 'Fever': 0.4}\n",
      "- Transmission Probabilities:  {'Healthy': {'Healthy': 0.69, 'Fever': 0.3, 'E': 0.01}, 'Fever': {'Healthy': 0.4, 'Fever': 0.59, 'E': 0.01}}\n",
      "- Emission Probabilities:  {'Healthy': {'normal': 0.5, 'cold': 0.4, 'dizzy': 0.1}, 'Fever': {'normal': 0.1, 'cold': 0.3, 'dizzy': 0.6}}\n",
      "- End State:  E \n",
      "\n",
      "Results:\n",
      "  Forward:  [{'Healthy': 0.3, 'Fever': 0.04000000000000001}, {'Healthy': 0.0892, 'Fever': 0.03408}, {'Healthy': 0.007518, 'Fever': 0.028120319999999997}]\n",
      "  Backwards:  [{'Healthy': 0.0010418399999999998, 'Fever': 0.00109578}, {'Healthy': 0.00249, 'Fever': 0.00394}, {'Healthy': 0.01, 'Fever': 0.01}]\n",
      "  Posterior:  [{'Healthy': 0.8770110375573259, 'Fever': 0.1229889624426741}, {'Healthy': 0.623228030950954, 'Fever': 0.3767719690490461}, {'Healthy': 0.2109527048413057, 'Fever': 0.7890472951586943}]\n"
     ]
    }
   ],
   "source": [
    "print(\"This example demonstrates the Forward-Backward algorithm\")\n",
    "states = ('Healthy', 'Fever')\n",
    "end_state = 'E'\n",
    "observations = ('normal', 'cold', 'dizzy')\n",
    "start_probability = {'Healthy': 0.6, 'Fever': 0.4}\n",
    "transition_probability = {\n",
    "   'Healthy' : {'Healthy': 0.69, 'Fever': 0.3, 'E': 0.01},\n",
    "   'Fever' : {'Healthy': 0.4, 'Fever': 0.59, 'E': 0.01},\n",
    "}\n",
    "emission_probability = {\n",
    "   'Healthy' : {'normal': 0.5, 'cold': 0.4, 'dizzy': 0.1},\n",
    "   'Fever' : {'normal': 0.1, 'cold': 0.3, 'dizzy': 0.6},\n",
    "}\n",
    "print(\"The Forware-Backward Algorithm consists of 3 steps:\")\n",
    "print(\"1.  Computing forward probabilities\\n\\t -  the probability of ending up in any particular state given the first k observations in the sequence\")\n",
    "print(\"2.  Computing backward probabilities\\n\\t -  the probability of observing the remaining observations given any starting point k\")\n",
    "print(\"3.  computing smoothed values.\\n\")\n",
    "print(\"- Sequence of Observations: \",observations)\n",
    "print(\"- Hidden States: \",states)\n",
    "print(\"- Start Probability: \",start_probability)\n",
    "print(\"- Transmission Probabilities: \",transition_probability)\n",
    "print(\"- Emission Probabilities: \",emission_probability)\n",
    "print(\"- End State: \",end_state,\"\\n\")\n",
    "\n",
    "print(\"Results:\")\n",
    "fwd,bkwd,post = fwd_bkw(observations,states,start_probability,transition_probability,emission_probability,end_state)\n",
    "print(\"  Forward: \",fwd)\n",
    "print(\"  Backwards: \",bkwd)\n",
    "print(\"  Posterior: \",post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialHMM(algorithm='viterbi', init_params='ste', n_components=3,\n",
      "        n_iter=10, params='ste', random_state=None, startprob_prior=1.0,\n",
      "        tol=0.01, transmat_prior=1.0, verbose=False)\n",
      "(-13.758752224145665, array([0, 1, 2, 2, 2]))\n",
      "MultinomialHMM(algorithm='viterbi', init_params='ste', n_components=3,\n",
      "        n_iter=10, params='ste', random_state=None, startprob_prior=1.0,\n",
      "        tol=0.01, transmat_prior=1.0, verbose=False)\n",
      "(-0.8813434435724581, array([2, 0, 1, 1, 1]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/hmmlearn/base.py:452: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_), framelogprob)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The functon distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/hmmlearn/base.py:460: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_),\n",
      "/usr/local/lib/python3.6/site-packages/hmmlearn/base.py:469: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_),\n",
      "/usr/local/lib/python3.6/site-packages/hmmlearn/base.py:624: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_),\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/hmmlearn/base.py:452: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_), framelogprob)\n"
     ]
    }
   ],
   "source": [
    "# Using the numpy built in HMM functions\n",
    "# Synthesize Data \n",
    "trans_mat  = np.array([[0.2, 0.6, 0.2],\n",
    "                     [0.4, 0.0, 0.6],\n",
    "                     [0.1, 0.2, 0.7]])\n",
    "emm_mat    = np.array([[0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "                    [0.1, 0.1, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1, 0.1],\n",
    "                    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2]])\n",
    "start_prob = np.array([0.3, 0.4, 0.3])\n",
    "X = [3,4,5,6,7]\n",
    "model = hmm.MultinomialHMM(n_components=3)\n",
    "model.startprob_ = start_prob\n",
    "model.transmat_  = trans_mat\n",
    "model.emissionprob_ = emm_mat\n",
    "\n",
    "# Predict the optimal sequence of internal hidden state\n",
    "X = np.atleast_2d([3, 4, 5, 6, 7]).T\n",
    "print(model)\n",
    "print(model.decode(X))\n",
    "remodel = hmm.GaussianHMM(n_components=3, n_iter=100)\n",
    "remodel.fit(X)\n",
    "print(model)\n",
    "print(remodel.decode(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
