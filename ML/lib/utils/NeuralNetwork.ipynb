{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import progressbar\n",
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "import loss_funcs as loss_funcs\n",
    "import optimizers as optimizers\n",
    "from activation_funcs import Sigmoid, ReLU, LeakyReLU, TanH, SoftMax\n",
    "bar_widgets = [\n",
    "    'Training: ', progressbar.Percentage(), ' ', progressbar.Bar(marker=\"-\", left=\"[\", right=\"]\"),\n",
    "    ' ', progressbar.ETA()\n",
    "]\n",
    "\n",
    "# Load datasets\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "data = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural Net Superclass\n",
    "class NeuralNet():\n",
    "    \"\"\"Generic class to model NeuralNet\n",
    "    \"\"\"\n",
    "    def __init__(self,optimizer,loss):\n",
    "        # initialize Neural Net superclass\n",
    "        self.loss      = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.layers    = []\n",
    "        self.errors    = {\"training\":[],\"validation\":[]}\n",
    "        self.X_val = np.empty([])\n",
    "        self.y_val = np.empty([])\n",
    "        \n",
    "    def addLayer(self,layer):\n",
    "        # if there are layers int he network already then, \n",
    "        #     set new layers input shape as previous layers output shape\n",
    "        if self.layers:\n",
    "            layer.set_input_shape(self.layers[-1].output_shape())\n",
    "            \n",
    "        # set optimizer\n",
    "        if hasattr(layer,'initialize'):\n",
    "            layer.initialize(self.optimizer)\n",
    "            \n",
    "        # add layer to list\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def train(self, X, y, n_epochs, batch_size):\n",
    "\n",
    "        # Convert to one-hot encoding\n",
    "        y = to_categorical(y.astype(\"int\"))  # binarize data\n",
    "\n",
    "        n_samples = np.shape(X)[0]\n",
    "        n_batches = int(n_samples / batch_size)\n",
    "        # To visualize progress\n",
    "        bar = progressbar.ProgressBar(widget=bar_widgets)\n",
    "        for _ in bar(range(n_epochs)):\n",
    "            # Shuflle through batches\n",
    "            idx = np.arange(n_samples)\n",
    "            np.random.shuffle(idx)\n",
    "\n",
    "            batch_t_error = 0   # Mean batch training error\n",
    "            for i in range(n_batches):\n",
    "                X_batch = X[idx[i*batch_size:(i+1)*batch_size]]\n",
    "                y_batch = y[idx[i*batch_size:(i+1)*batch_size]]\n",
    "                loss, _ = self.train_on_batch(X_batch, y_batch)\n",
    "                batch_t_error += loss\n",
    "\n",
    "            # Save the epoch mean error\n",
    "            self.errors[\"training\"].append(batch_t_error / n_batches)\n",
    "            if self.X_val.any():\n",
    "                # Calculate the validation error\n",
    "                y_val_p = self._forward_pass(self.X_val)\n",
    "                validation_loss = np.mean(self.loss.function(self.y_val, y_val_p))\n",
    "                #self.errors[\"validation\"].append(validation_loss)\n",
    "\n",
    "        return self.errors[\"training\"], None#self.errors[\"validation\"]\n",
    "    \n",
    "    def train_on_batch(self, X, y):\n",
    "        # Calculate output\n",
    "        y_pred = self._forward_pass(X)\n",
    "        # Calculate the training loss\n",
    "        loss = np.mean(self.loss.function(y, y_pred))\n",
    "        # Calculate the gradient of the loss function wrt y_pred\n",
    "        loss_grad = self.loss.gradient(y, y_pred)\n",
    "        # Calculate the accuracy of the prediction\n",
    "        ##acc = self.loss.acc(y, y_pred)\n",
    "        # Backprop. Update weights\n",
    "        self._backward_pass(loss_grad=loss_grad)\n",
    "        \n",
    "        return loss, None\n",
    "\n",
    "    def set_trainingState(self,trainingState = True):\n",
    "        for layer in self.layers:\n",
    "            layer.trainable = trainingState\n",
    "            \n",
    "    def _forward_pass(self, X, training=True):\n",
    "        # Calculate the output of the NN. The output of layer l1 becomes the\n",
    "        # input of the following layer l2\n",
    "        layer_output = X\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer.forward_pass(layer_output, training)\n",
    "\n",
    "        return layer_output\n",
    "\n",
    "    def _backward_pass(self, loss_grad):\n",
    "        # Propogate the gradient 'backwards' and update the weights\n",
    "        # in each layer\n",
    "        acc_grad = loss_grad\n",
    "        for layer in reversed(self.layers):\n",
    "            acc_grad = layer.backward_pass(acc_grad)\n",
    "            \n",
    "    # Use the trained model to predict labels of X\n",
    "    def predict(self, X):\n",
    "        return self._forward_pass(X, training=False)\n",
    "    \n",
    "    # use the trained model to hallucinate X\n",
    "    def backQuery(self,y):\n",
    "        layer_output = y\n",
    "        self.set_trainingState(trainingState = False)\n",
    "        \n",
    "        for layer in reversed(self.layers):\n",
    "            layer_output = layer.backwardQuery(layer_output)\n",
    "        return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Layer subclass\n",
    "class Layer(object):\n",
    "    \"\"\" \n",
    "    Layer SuperClass\n",
    "    \"\"\"\n",
    "    def set_input_shape(self,shape):\n",
    "        self.input_shape = shape\n",
    "    \n",
    "    def get_layer_name(self):\n",
    "        return self.__class__.__name__\n",
    "    \n",
    "# Types of layers sub-sub-class\n",
    "class Dense(Layer):\n",
    "    \"\"\"\n",
    "    fully-connected NN layer --> subclass of Layer SuperClass.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_units:     [int] The number of nodes in the layer.\n",
    "    input_shape: [tuple] The expected input shape of the layer. single digit for Dense.\n",
    "                 -  Must be specified if it is the first layer in the network.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_units, input_shape=None):\n",
    "        self.layer_input = None\n",
    "        self.initialized = False\n",
    "        self.trainable   = True\n",
    "        self.W  = None\n",
    "        self.wb = None # bias term\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.n_units     = n_units\n",
    "        \n",
    "    def initialize(self,optimizer):\n",
    "        nodes_in  = self.input_shape[0]\n",
    "        nodes_out = self.n_units\n",
    "        bound     = 1 / math.sqrt(nodes_in)\n",
    "        # initialize weights to be Normal distribution ND(1/sqrt(n_in))\n",
    "        self.W  = np.random.normal(-bound,bound,(nodes_in,nodes_out))\n",
    "        self.wb = np.zeros((1,nodes_out)) # bias term\n",
    "        # return a copy of user specified optimizer\n",
    "        self.W_opt  = copy.copy(optimizer)\n",
    "        self.wb_opt = copy.copy(optimizer)\n",
    "        \n",
    "    def forward_pass(self, X, training=True):\n",
    "        # linear regression\n",
    "        self.layer_input = X\n",
    "        return X.dot(self.W) + self.wb\n",
    "\n",
    "    def backward_pass(self, prop_grad):\n",
    "        # Propagate gradients backwards through NN to update layer weights\n",
    "        \n",
    "        W = self.W # store weights in memory\n",
    "\n",
    "        if self.trainable:\n",
    "            # Calculate gradient w.r.t layer weights\n",
    "            grad_w  = np.dot(self.layer_input.T,prop_grad)\n",
    "            grad_wb = np.sum(prop_grad, axis=0, keepdims=True)\n",
    "\n",
    "            # Update the layer weights\n",
    "            self.W  = self.W_opt.update(self.W, grad_w)\n",
    "            self.wb = self.wb_opt.update(self.wb, grad_wb)\n",
    "\n",
    "        # Return propagated gradient for next layer\n",
    "        # Calculated based on the weights used during the forward pass\n",
    "        prop_grad = np.dot(prop_grad,W.T)\n",
    "        \n",
    "        return prop_grad \n",
    "    \n",
    "    def backwardQuery(self,layer_output):\n",
    "        layer_output = np.dot(layer_output,self.W.T)\n",
    "        layer_output -= np.min(layer_output)\n",
    "        layer_output /= np.max(layer_output)\n",
    "        layer_output *= 0.98\n",
    "        layer_output += 0.01\n",
    "        return layer_output\n",
    "\n",
    "    def output_shape(self):\n",
    "        return (self.n_units,)\n",
    "    \n",
    "class Dropout(Layer):\n",
    "    \"\"\"A layer that randomly sets a fraction of previous layer output units to zero.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    p: [float]  The probability that unit x is set to zero.\n",
    "    \"\"\"\n",
    "    def __init__(self, p = 0.2):\n",
    "        self.p            = p\n",
    "        self._mask        = None\n",
    "        self.input_shape  = None\n",
    "        self.n_units      = None\n",
    "        self.pass_through = True\n",
    "        self.trainable    = True\n",
    "    \n",
    "    def forward_pass(self, X, training=True):\n",
    "        c = (1 - self.p)\n",
    "        if training:\n",
    "            self._mask = np.random.uniform(size=X.shape) > self.p\n",
    "            c = self._mask\n",
    "        return X * c\n",
    "\n",
    "    def backward_pass(self, prop_grad):\n",
    "        return prop_grad * self._mask\n",
    "    \n",
    "    def backwardQuery(self,layer_output):\n",
    "        return layer_output\n",
    "\n",
    "    def output_shape(self):\n",
    "        return self.input_shape\n",
    "    \n",
    "class Activation(Layer):\n",
    "    \"\"\"A layer that applies an activation operation to the input.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    name: string\n",
    "        The name of the activation function that will be used. \n",
    "    \"\"\"\n",
    "    activation_functions = {\n",
    "        'relu': ReLU,\n",
    "        'sigmoid': Sigmoid,\n",
    "        'softmax': SoftMax,\n",
    "        'leaky_relu': LeakyReLU,\n",
    "        'tanh': TanH,\n",
    "    }\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.activation_name = name\n",
    "        self.activation      = self.activation_functions[name]()\n",
    "        self.trainable       = True\n",
    "\n",
    "    def forward_pass(self, X, training=True):\n",
    "        self.layer_input = X\n",
    "        return self.activation.function(X)\n",
    "\n",
    "    def backward_pass(self, prop_grad):\n",
    "        return prop_grad * self.activation.gradient(self.layer_input)\n",
    "    \n",
    "    def backwardQuery(self,layer_output):\n",
    "        return self.activation.ifunction(layer_output)\n",
    "    \n",
    "    def output_shape(self):\n",
    "        return self.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 3 4 ..., 5 6 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (50 of 50) |#########################| Elapsed Time: 0:03:00 Time: 0:03:00\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding of nominal values\n",
    "def to_categorical(x):\n",
    "    n_col = np.amax(x) + 1\n",
    "    binarized = np.zeros((len(x), n_col))\n",
    "    for i in range(len(x)):\n",
    "        binarized[i, x[i]] = 1\n",
    "\n",
    "    return binarized\n",
    "# Split the data into train and test sets\n",
    "def shuffle_data(X, y, seed=None):\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    n_samples = X.shape[0]\n",
    "    idx = np.arange(n_samples)\n",
    "    np.random.shuffle(idx)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "    return X, y\n",
    "\n",
    "def train_test_split(X, y, test_size=0.5, shuffle=True, seed=None):\n",
    "    if shuffle:\n",
    "        X, y = shuffle_data(X, y, seed)\n",
    "    # Split the training data from test data in the ratio specified in\n",
    "    # test_size\n",
    "    split_i = len(y) - int(len(y) // (1 / test_size))\n",
    "    x_train, x_test = X[:split_i], X[split_i:]\n",
    "    y_train, y_test = y[:split_i], y[split_i:]\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "X = mnist.train.images\n",
    "y = np.argmax(mnist.train.labels,axis=1)#data.target\n",
    "\n",
    "#X = data.data\n",
    "#Y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, seed=1)\n",
    "\n",
    "n_samples = np.shape(X)\n",
    "\n",
    "J    = loss_funcs.CrossEntropy()\n",
    "opt  = optimizers.Adam()\n",
    "\n",
    "nmodel = NeuralNet(optimizer= opt,loss=J)\n",
    "h1_d   = Dense(200,input_shape=(28*28,))\n",
    "a1     = Activation('sigmoid')\n",
    "d1     = Dropout(0.25)\n",
    "h2_d   = Dense(200,input_shape=(200,))\n",
    "a2     = Activation('sigmoid')\n",
    "d2     = Dropout(0.20)\n",
    "h3_d   = Dense(10,input_shape=(200,))\n",
    "a3     = Activation('softmax')\n",
    "d3     = Dropout(0.20)\n",
    "\n",
    "\n",
    "nmodel.addLayer(h1_d)\n",
    "nmodel.addLayer(a1)\n",
    "#nmodel.addLayer(d1)\n",
    "#nmodel.addLayer(h2_d)\n",
    "#nmodel.addLayer(a2)\n",
    "#nmodel.addLayer(d2)\n",
    "nmodel.addLayer(h3_d)\n",
    "nmodel.addLayer(a3)\n",
    "#nmodel.addLayer(d3)\n",
    "train_err,val_err = nmodel.train(X_train, y_train, n_epochs=50, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dae51d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Layer.get_layer_name of <__main__.Dense object at 0x10dae5a58>> (784,)\n",
      "<bound method Layer.get_layer_name of <__main__.Activation object at 0x10dae5c50>> (200,)\n",
      "<bound method Layer.get_layer_name of <__main__.Dense object at 0x10dae5be0>> (200,)\n",
      "<bound method Layer.get_layer_name of <__main__.Activation object at 0x10dad4e48>> (10,)\n",
      "Model Accuracy: 0.921182\n"
     ]
    }
   ],
   "source": [
    "plt.plot(train_err)\n",
    "plt.show()\n",
    "[print(lay.get_layer_name,lay.input_shape) for lay in nmodel.layers]\n",
    "yhat   = nmodel.predict(X_test)\n",
    "ylabel = np.argmax(yhat,axis=1)\n",
    "testscore = ylabel == y_test\n",
    "testscore.astype(int)\n",
    "print(\"Model Accuracy: %2f\"%(np.sum(testscore)/len(testscore)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01  0.01  0.01  0.01  0.01  0.01  0.99  0.01  0.01  0.01]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJKXkF0nq/wDTXy2nSVvkjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c4f8d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Not hallucinating correctly\n",
    "label = 6\n",
    "y_hallucinate = np.zeros(10)+0.01\n",
    "y_hallucinate[label] = 0.99\n",
    "print(y_hallucinate)\n",
    "x_hallucinate = nmodel.backQuery(y_hallucinate)\n",
    "plt.imshow(np.reshape(x_hallucinate,(28,28)), cmap='Greys', interpolation='None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
